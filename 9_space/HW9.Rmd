---
title: "Homework N Responses"
author: "Zeyi Han, Shubhi Sharma, Margaret Swift"
date: '`r Sys.Date()`'
output:
  prettydoc::html_pretty:
    theme: architect
    highlight: github
---

```{r setup, include=F}
#----------------------------------------------------------------------------
# LOADING
knitr::opts_chunk$set(echo=FALSE, eval=TRUE, cache=FALSE)
pacman::p_load(CARBayes, CARBayesdata, classInt, coda, fields, geomapdata, geoR, gjam, gtools, knitr, lattice, mapdata, maps, maptools, MASS, MBA, plyr, RANN, RColorBrewer, reshape2, rgdal, sp, spBayes, spdep)
source('../clarkfunctions2020.R')
# Rcpp::sourceCpp('../cppFns.cpp')
# any libraries and data here

#----------------------------------------------------------------------------
# FUNCTIONS
# put functions here

```


## Exercise 1 {#q1}

_Select a species to fit.  Use AIC as a model selection criterion to determine which combination of variables in `xdata` best fits the data._

```{r q1}
#----------------------------------------------------------------------------
## EXERCISE 1

```


## Exercise 2 {#q2}

_Do you believe that the MCMC converged to a posterior distribution?  If not, what might you do to convince yourself?_

```{r q2}
#----------------------------------------------------------------------------
## EXERCISE 2

```


## Exercise 3 {#q3}


_Divide up your group so that each determines how one of the following influences model selection.  Use DIC as your criterion._

_1. Different numbers of knots_

_2. Prior distributions on $\sigma^2$._

_3. Prior distributions on $\phi$._

```{r q3}
#----------------------------------------------------------------------------
## EXERCISE 3

a3 <- as.data.frame(cbind(ModelName = c("3a1", "3a2", "3a3", "3a4"), knots = c(20, 30, 40, 50), DIC = c(-123181, -123932 , -124462.4,  -123794.1)))

knitr::kable(a3)

a4 <- as.data.frame(cbind(ModelName = c("3b1", "3b2", "3b3", "3d4"), lo = c(0.1, 0, 0, 0), hi = c(2, 4, 10, 10), mu =c(0.05, 0.05, 3, 0.05), sig =c(1, 1, 1, 5)))

knitr::kable(a4)

a5 <- as.data.frame(cbind(ModelName = c("3c1", "3c2", "3c3", "3c4"), lo = c(0, 0, 0, 0), hi = c(3, 10, 10, 10), mu = c(3, 6, 6, 3), sig = c(1, 1, 10, 12)))

knitr::kable(a5)

```


## Exercise 4 {#q4}

_Interpret the contributions of the mean and the spatial random effects to predicted surfaces.  In other words, what do they mean?_

```{r q4}
#----------------------------------------------------------------------------
## EXERCISE 4

```


## Exercise 5 {#q5}

_Repeat exercise 3 with GJAM and compare results for the two models.  If there are differences, can you explain them?_

```{r q5}
#----------------------------------------------------------------------------
## EXERCISE 5

```

## Exercise 6 {#q6}

_Repeat the spatial analysis with a binomial model.  Use the `CARBayes` help page.  Interpret the analysis._

```{r q6}
#----------------------------------------------------------------------------
## EXERCISE 6

# Existing simulation code **************************************************
m <- 12
n <- m^2
Q <- 3
sigma <- .1

xEast  <- xNorth <- 1:m
grid   <- expand.grid(xEast, xNorth)
D <- W <- as.matrix(dist(grid))
W[W!=1]<- 0  

x     <- matrix( rnorm(Q*n), n, Q )
x[,1] <- 1; x2 <- x[,2]; x3 <- x[,3]
beta  <- matrix( rnorm(Q), Q, 1)
phi   <- mvrnorm(1, rep(0,n), 1*exp(-0.1*D) )
form  <- as.formula(y ~ x2 + x3)

# Binomial model ************************************************************
# Generate random no. of trials, mean 20; log-odds link for probabilities
sizes<- rpois(n=n, lambda=20)
p    <- inv.logit(x%*%beta + phi + rnorm(n, 0, sigma))
y    <- rbinom(length(phi), sizes, prob=p)

binomialModel <- S.CARbym(formula=form, family="binomial", trials=sizes,
                          W=W, burnin=600, n.sample=10000, thin=10, verbose=F)
binomialModel
dic <- round(binomialModel$modelfit[1])
```

In order to perform an analysis on a binomial model, we randomly generated vectors of (1) trial `sizes` using `rpois` with an arbitrary mean of 20 trials, (2) probability of success `p` using the inverse logit function (as binomial models use logit link), and (3) responses `y` using a binomial random variable `rbinom`. The true parameter values are contrasted with predicted in the table below:

```{r}
df <- data.frame(true=c(round(beta, 3), sigma),
                 pred=binomialModel$summary.results[c(1:3,5),1])
kable(df, caption="True vs. predicted parameters.")
```

Since these data are re-generated randomly every time we knit this document, we cannot comment on particular values of predicted vs. true parameters. However, over a few different runs, we noticed that while `x2` and `x3` are predicted relatively well by this process, the intercept is often predicted to have the opposite sign from the true, and the variance `sigma2` is frequently predicted to be an order of magnitude smaller than the true value. 


## Exercise 7 {#q7}
_Work through the lip cancer example in groups as if you were attempting to apply it to a data set of your own._

```{r q7}
#----------------------------------------------------------------------------
## EXERCISE 7
data(lipdata)
data(lipdbf)
data(lipshp)
kable(summary(lipdata), caption="Summary Statistics")

lipdbf$dbf    <- lipdbf$dbf[ ,c(2,1)]
data.combined <- combine.data.shapefile(data=lipdata, shp=lipshp, dbf=lipdbf)

# map of neighbors
nb.bound <- poly2nb(data.combined) 
coords   <- coordinates(data.combined)
plot(data.combined, border = "gray", main="Scottland")
plot(nb.bound, coords, pch = 19, cex = 0.6, add = TRUE)

# The map shows the neighbors. Here are maps of data:
breakpoints <- seq(min(lipdata$observed)-1, max(lipdata$observed)+1, length.out=8)
my.palette <- brewer.pal(n = 7, name = "OrRd")

spplot(data.combined, c("observed", "expected"), 
       main="Scottish Lip Cancer",at=breakpoints,
       col.regions=my.palette, col="grey")

# Here is the pcaff variable, one of the predictors in the model:
spplot(data.combined, c("observed", "pcaff"), 
       main="Scottish Lip Cancer", at=breakpoints,
       col.regions=my.palette, col="black")

# Linear model (GLM)
glmmodel <- glm(observed~., family="poisson", data=data.combined@data)
resid.glmmodel <- residuals(glmmodel)

W.nb    <- poly2nb(data.combined, row.names = rownames(data.combined@data))
W.list  <- nb2listw(W.nb, style="B")
testglm <- moran.mc(x=resid.glmmodel, listw=W.list, nsim=1000)
W       <- nb2mat(W.nb, style="B")
formula <- observed ~ expected+pcaff+latitude+longitude
model.spatial1 <- S.CARleroux(formula=formula,
                              data=data.combined@data,family="gaussian", 
                              W=W, burnin=5000, n.sample=10000, thin=10, verbose=F)
betas1 <- summarise.samples(model.spatial1$samples$beta, 
                            quantiles=c(0.5, 0.025, 0.975))
resultsMS1 <- betas1$quantiles
rownames(resultsMS1) <- c("Intercept", "Expected", "Pcaff", "Latitude", "Longitude")
kable(resultsMS1, caption="95% Credible Intervals Model 1")

# Nonlinear model
model.spatial2 <- S.CARleroux(formula=formula,
                              data=data.combined@data,family="poisson", 
                              W=W, burnin=5000, n.sample=10000, thin=10, verbose=FALSE)
betas2 <- summarise.samples(model.spatial2$samples$beta, quantiles=c(0.5, 0.025, 0.975))
resultsMS2 <- betas2$quantiles
rownames(resultsMS2) <- c("Intercept", "Expected", "Pcaff", "Latitude", "Longitude")
kable(resultsMS2, caption="95% Credible Intervals Model 2")

# Here is another option with piecewise intercepts set by the constant G.
model.spatial3 <- S.CARlocalised(formula=formula, G=5,
                                 data=data.combined@data,family="poisson", 
                                 W=W, burnin=5000, n.sample=10000, thin=10,
                                 verbose=FALSE)
betas3 <- summarise.samples(model.spatial3$samples$beta, 
                            quantiles=c(0.5, 0.025, 0.975))
resultsMS3 <- betas3$quantiles
rownames(resultsMS3) <- c("Expected", "Pcaff", "Latitude", "Longitude")
kable(resultsMS3, caption="95% Credible Model 3")
```


## Appendix {#appendix}

```{r ref.label=knitr::all_labels(), echo = T, eval = F}
```


