lines(year, spec.quant[2,], lty=2, lwd=2)
lines(year, spec.quant[4,], lwd=5, col='white')
lines(year, spec.quant[4,], lty=2, lwd=2)
title(spec)
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# JAGS
# Save wood thrush model to text file
file <- "jagsWoodThrush.txt"                # model file
cat("model{
for(i in 1:n){
Y[i] ~ dpois(lambda[i])                  # stochastic Y
lambda[i] <- exp( inprod(beta[],X[i,]) ) # lambda deterministic
}
for (i in 1:p) {
beta[i] ~ dnorm(0, 1.0E-5)
}
}", file = file)
# Create a factor version for each variable
xdata$routeFactor     <- as.factor(xdata$Route)
xdata$StartWindFactor <- as.factor(xdata$StartWind)
xdata$SkyFactor       <- as.factor(xdata$StartSky)
# Fill in X and Y
xmiss <- which(is.na(xdata),arr.ind=T)
X <- model.matrix(y ~ temp + year + StartWindFactor, data=xdata)
Y <- model.frame(y ~ temp + year + StartWindFactor, data=xdata)$y
dataList <- list(Y = Y, X = X, n = nrow(X), p = ncol(X))
save(dataList,file='jagsData.Rdata')
# computation
outjags <- jags.model(data=dataList, inits=NULL, file=file,
n.chains=3, n.adapt=500 )
install.packages("tidyr")
lambda <- 0.2
N <- 1000
Y1 <- rexp(N, lambda)
Y2 <- rexp(N, lambda)
S <- Y1 + Y2
D <- Y1 - Y2
plot(S, D)
library(ggplot2)
lambda <- 0.2
N <- 1000
Y1 <- rexp(N, lambda)
Y2 <- rexp(N, lambda)
S <- Y1 + Y2
D <- Y1 - Y2
SD.df <- data.frame(S=S, D=D)
ggplot(SD.df, aes(x=S, y=D)) + geom_point()
library(ggplot2)
lambda <- 20
N <- 1000
Y1 <- rexp(N, lambda)
Y2 <- rexp(N, lambda)
S <- Y1 + Y2
D <- Y1 - Y2
SD.df <- data.frame(S=S, D=D)
ggplot(SD.df, aes(x=S, y=D)) + geom_point()
library(ggplot2)
lambda <- 20
N <- 135
Y1 <- rexp(N, lambda)
Y2 <- rexp(N, lambda)
S <- Y1 + Y2
D <- Y1 - Y2
SD.df <- data.frame(S=S, D=D)
ggplot(SD.df, aes(x=S, y=D)) + geom_point()
library(ggplot2)
lambda <- 20
N <- 1e5
Y1 <- rexp(N, lambda)
Y2 <- rexp(N, lambda)
S <- Y1 + Y2
D <- Y1 - Y2
SD.df <- data.frame(S=S, D=D)
ggplot(SD.df, aes(x=S, y=D)) + geom_point()
library(ggplot2)
lambda <- 20
N <- 1e4
Y1 <- rexp(N, lambda)
Y2 <- rexp(N, lambda)
S <- Y1 + Y2
D <- Y1 - Y2
SD.df <- data.frame(S=S, D=D)
ggplot(SD.df, aes(x=S, y=D)) + geom_point()
library(ggplot2)
lambda <- 0.2
N <- 1e3
Y1 <- rexp(N, lambda)
Y2 <- rexp(N, lambda)
S <- Y1 + Y2
D <- Y1 - Y2
SD.df <- data.frame(S=S, D=D)
ggplot(SD.df, aes(x=S, y=D)) + geom_point()
library(ggplot2)
lambda <- 0.2
N <- 1e3
Y1 <- rexp(N, lambda)
Y2 <- rexp(N, lambda)
S <- Y1 + Y2
D <- Y1 - Y2
SD.df <- data.frame(S=S, D=D)
ggplot(SD.df, aes(x=S, y=D)) + geom_point(pch=1)
PdD <- 1/(2*lambda**2)
PdD
PdD <- 1/(2*(lambda**2))*exp(-S/lambda)
PdD <- 1/(2*(lambda**2))*exp(-S/lambda)
hist(PdD)
hist(PdD, breaks=100)
hist(PdD, breaks=1000)
hist(PdD, breaks=100)
?hist
hist(PdD, breaks=100)
hist(PdD, breaks=100, xlim=c(0,2))
hist(PdD, breaks=100, xlim=c(0,0.5))
hist(PdD, breaks=1000, xlim=c(0,0.5))
lambda
4 **2
PdD <- 1/(2*(lambda**2))*exp(-(Y1+Y2)/lambda)
hist(PdD, breaks=1000, xlim=c(0,0.5))
PdD <- 1/(2*(lambda**2))*exp(-S/lambda)
hist(PdD, breaks=1000, xlim=c(0,0.5))
hist(PdD, breaks=1000, xlim=c(0,0.05))
hist(PdD, breaks=1000, xlim=c(0,0.005))
hist(PdD, breaks=10000, xlim=c(0,0.005))
hist(PdD, breaks=100)
plot(S, PdD)
plot(S, PdD, xlim=c(0, 10))
PdD <- 1/(2*(lambda**2))*exp(-S/lambda)
PdD.df <- data.frame(S=S, PdD=PdD)
ggplot(PdD.df, aes(x=S, y=PdD)) + geom_line()
ggplot(SD.df, aes(x=S, y=D)) + geom_point(pch=1)
ggplot(PdD.df, aes(x=S, y=PdD)) + geom_line()
PdD <- -1/(2*(lambda**2))*(1-exp(-D/lambda))
PdD.df <- data.frame(D=D, PdD=PdD)
ggplot(PdD.df, aes(x=D, y=PdD)) + geom_line()
hist(pdD)
hist(PdD)
hist(PdD, breaks=100)
ggplot(PdD.df, aes(x=D, y=PdD)) + geom_line()
beta <- matrix(rnorm(Q), Q, 1)
n <- 100
Q <- 5
beta <- matrix(rnorm(Q), Q, 1)
beta
i
x <- matrix( rnorm(n*Q), n, Q )
x
dim(x)
x[,1] <- 1
dim(x)
head(x)
sigma <- 0.1
y <- x%*%beta
epsilon <- rnorm(n, 0, sigma)
y <- x%*%beta + epsilon
y
dim(y)
n <- 100
Q <- 5
sigma <- 0.1
epsilon <- rnorm(n, 0, sigma)
beta <- matrix( rnorm(Q), Q, 1 )
x <- matrix( rnorm(n*Q), n, Q )
x[,1] <- 1 #set intercept
y <- x%*%beta + epsilon
dim(y)
plot(y)
# simulate data
genData <- function(n, Q, sigma) {
epsilon <- rnorm(n, 0, sigma)
beta <- matrix( rnorm(Q), Q, 1 )
x <- matrix( rnorm(n*Q), n, Q )
x[,1] <- 1 #set intercept
y <- x%*%beta + epsilon
return(list(x=x, y=y, beta=beta, epsilon=epsilon))
}
n <- 100
Q <- 5
sigma <- 0.1
genData(n, Q, sigma)
data <- genData(n, Q, sigma)
data$x
B <- diag(1000, Q)
B
# ---------------------------------------------------
# FUNCTIONS
genData <- function(n, Q, sigma) {
epsilon <- rnorm(n, 0, sigma)
beta <- matrix( rnorm(Q), Q, 1 )
x <- matrix( rnorm(n*Q), n, Q )
x[,1] <- 1 #set intercept
y <- x%*%beta + epsilon
out <- list(x=x, y=y, beta=beta, epsilon=epsilon,
params=list(Q=Q, n=n, sigma=sigma))
return(out)
}
# ---------------------------------------------------
# LET'S GO
data <- genData(n=100, Q=5, sigma=0.1)
epsilon <- rnorm(n, 0, sigma)
beta <- matrix( rnorm(Q), Q, 1 )
x <- matrix( rnorm(n*Q), n, Q )
x[,1] <- 1 #set intercept
y <- x%*%beta + epsilon
b <- matrix(0, Q, 1)
B <- diag(1000, Q)
VI <- 1/sigma/sigma * crossprod(x) + solve(B)
V <- solve(VI)
v <- 1/sigma/sigma * crossprod(x,y) + solve(B)%*%b
dim(V)
V
dim(VI)
dim(v)
v
sqrt(diag(V))
beta
solve(B)
B
x
sderrors <- sqrt(diag(V))
V%*%v
beta
solve(B)
# scratchData.R
# simulate data
getwd()
# ---------------------------------------------------
# FUNCTIONS
genData <- function(n, Q, sigma) {
epsilon <- rnorm(n, 0, sigma)
beta <- matrix( rnorm(Q), Q, 1 )
x <- matrix( rnorm(n*Q), n, Q )
x[,1] <- 1 #set intercept
y <- x%*%beta + epsilon
b <- matrix(0, Q, 1)
B <- diag(1000, Q) #priors are horrible, so I give it a wide variance
B.inv <- solve(B)
V.inv <- 1/sigma/sigma * crossprod(x) + B.inv
V <- solve(V.inv) #covariance matrix of beta
v <- 1/sigma/sigma * crossprod(x,y) + B.inv%*%b
sderrors <- sqrt(diag(V))
mu <- V%*%v
return(out)
}
# scratchData.R
# simulate data
source('../clarkFunctions2020.R')
bstar <- .rMVN(1, mu, V)
epsilon <- rnorm(n, 0, sigma)
beta <- matrix( rnorm(Q), Q, 1 )
x <- matrix( rnorm(n*Q), n, Q )
x[,1] <- 1 #set intercept
y <- x%*%beta + epsilon
b <- matrix(0, Q, 1)
B <- diag(1000, Q) #priors are horrible, so I give it a wide variance
B.inv <- solve(B)
V.inv <- 1/sigma/sigma * crossprod(x) + B.inv
V <- solve(V.inv) #covariance matrix of beta
v <- 1/sigma/sigma * crossprod(x,y) + B.inv%*%b
sderrors <- sqrt(diag(V))
# Now we should estimate betas!
mu <- V%*%v
bstar <- .rMVN(1, mu, V)
bstar
beta
bstar <- transpose(.rMVN(1, mu, V))
bstar <- T(.rMVN(1, mu, V))
bstar <- t(.rMVN(1, mu, V))
bstar
bstar <- t(.rMVN(1000, mu, V))
dim(bstar)
colmeans(bstar)
colMeans(bstar)
dim(bstar)
# And generating random values from this distn we know now
bstar <- .rMVN(1000, mu, V)
colMeans(bstar)
PdD <- -1/(2*(lambda**2))*(exp(-D/lambda)-exp(s/lambda))
PdD.df <- data.frame(D=D, PdD=PdD)
library(ggplot2)
lambda <- 0.2
N <- 1e3
Y1 <- rexp(N, lambda)
Y2 <- rexp(N, lambda)
S <- Y1 + Y2
D <- Y1 - Y2
SD.df <- data.frame(S=S, D=D)
ggplot(SD.df, aes(x=S, y=D)) + geom_point(pch=1)
PdD <- -1/(2*(lambda**2))*(exp(-D/lambda)-exp(s/lambda))
PdD.df <- data.frame(D=D, PdD=PdD)
ggplot(PdD.df, aes(x=D, y=PdD)) + geom_line()
library(ggplot2)
lambda <- 0.2
N <- 1e3
Y1 <- rexp(N, lambda)
Y2 <- rexp(N, lambda)
S <- Y1 + Y2
D <- Y1 - Y2
SD.df <- data.frame(S=S, D=D)
ggplot(SD.df, aes(x=S, y=D)) + geom_point(pch=1)
PdD <- -1/(2*(lambda**2))*(exp(-D/lambda)-exp(S/lambda))
PdD.df <- data.frame(D=D, PdD=PdD)
ggplot(PdD.df, aes(x=D, y=PdD)) + geom_line()
ggplot(PdD.df, aes(x=D, y=PdD)) + geom_line() + xlim(c(-1,1))
ggplot(PdD.df, aes(x=D, y=PdD)) + geom_line()
ggplot(PdD.df, aes(x=D, y=PdD)) + geom_line() + xlim(10,20)
ggplot(PdD.df, aes(x=D, y=PdD)) + geom_line() + xlim(12.5,15)
hist(PdD)
hist(PdD, breaks=200)
library(ggplot2)
lambda <- 0.2
N <- 1e3
Y1 <- rexp(N, lambda)
Y2 <- rexp(N, lambda)
S <- Y1 + Y2
D <- Y1 - Y2
hist(D)
hist(D, breaks=100)
# new sigma?
u1 <- u2 <- 1
sigma2 <- rgamma(u1 +n/2, u2+1/2+crossprod(y-x%*%beta))
# new sigma?
u1 <- u2 <- 1
sigma2 <- rgamma(u1 +n/2, u2+1/2+crossprod(y-x%*%beta))
sigma2
sqrt(sigma2)
sigma2 <- rgamma(u1 +n/2, u2+0.5+crossprod(y-x%*%beta))
sqrt(sigma2)
sigma2 <- 1/rgamma(u1 +n/2, u2+0.5+crossprod(y-x%*%beta))
sqrt(sigma2)
sigma2 <- 1/rgamma(1,u1 +n/2, u2+0.5+crossprod(y-x%*%beta))
sqrt(sigma2)
sigma2 <- 1/rgamma(1, u1+(n/2), u2+0.5+crossprod(y-x%*%beta))
sqrt(sigma2)
sigma2 <- 1/rgamma(1, u1+(n/2), u2+0.5*crossprod(y-x%*%beta))
sqrt(sigma2)
sigma - sqrt(sigma2)
library(ggplot2)
lambda <- 0.2
N <- 1e3
Y1 <- rexp(N, lambda)
Y2 <- rexp(N, lambda)
S <- Y1 + Y2
D <- Y1 - Y2
SD.df <- data.frame(S=S, D=D)
ggplot(SD.df, aes(x=S, y=D)) + geom_point(pch=1)
PdD <- -1/(2*(lambda**2))*(exp(-D/lambda)-exp(S/lambda))
PdD.df <- data.frame(D=D, PdD=PdD)
ggplot(PdD.df, aes(x=D, y=PdD)) + geom_line() + xlim(12.5,15)
hist(D, breaks=100)
ggplot(PdD.df, aes(x=D, y=PdD)) + geom_line() + xlim(12.5,15)
ggplot(PdD.df, aes(x=D, y=PdD)) + geom_line()
library(ggplot2)
lambda <- 0.2
N <- 1e3
Y1 <- rexp(N, lambda)
Y2 <- rexp(N, lambda)
S <- Y1 + Y2
D <- Y1 - Y2
SD.df <- data.frame(S=S, D=D)
ggplot(SD.df, aes(x=S, y=D)) + geom_point(pch=1)
#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# LOADING
rm(list=ls())
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
getwd()
# Parameters
epsilon <- rnorm(n, 0, sigma)
# LOADING
rm(list=ls())
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
source('../clarkFunctions2020.R')
#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# MAIN
n=100; Q=5; sigma=0.1
# Parameters
epsilon <- rnorm(n, 0, sigma)
beta <- matrix( rnorm(Q), Q, 1 )
# Simulate x and y
x <- matrix( rnorm(n*Q), n, Q )
x[,1] <- 1 #set intercept
y <- x%*%beta + epsilon
head(x)
#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# FUNCTIONS
genData <- function(n, Q, sigma) {
# Parameters
epsilon <- rnorm(n, 0, sigma)
beta <- matrix( rnorm(Q), Q, 1 )
# Simulate x and y
x <- matrix( rnorm(n*Q), n, Q )
x[,1] <- 1 #set intercept
y <- x%*%beta + epsilon
# Return data
data <- list(x=x, y=y, beta=beta, n=n, Q=Q, sigma=sigma, epsilon=epsilon)
return(data)
}
data <- genData(n=n, Q=Q, sigma=sigma)
# GIBBS SAMPLING
Q=d$Q; x=d$x; y=d$y; n=d$n
gibbs <- function(d, nstep=1000) {
# GIBBS SAMPLING
Q=d$Q; x=d$x; y=d$y; n=d$n
for (i in 1:nstep) {
# Now to set up to find mu
b <- matrix(0, Q, 1)
B <- diag(1000, Q) #priors are horrible, so I give it a wide variance
B.inv <- solve(B)
# Find mu and standard errors
V.inv <- 1/sigma2/sigma2 * crossprod(x) + B.inv
V <- solve(V.inv) #covariance matrix of beta
v <- 1/sigma2/sigma2 * crossprod(x,y) + B.inv%*%b
sderrors <- sqrt(diag(V))
mu <- V%*%v
# And generating random values from this distn we know now
bstar <- .rMVN(1000, mu, V)
colMeans(bstar) #approaches mu
# new sigma
u1 <- u2 <- 1
# sigma2 <- 1/rgamma(1, u1+(n/2), u2+0.5*crossprod(y-x%*%beta))
# but we're using beta here... should I be using mu then?
sigma2 <- 1/rgamma(1, u1+(n/2), u2+0.5*crossprod(y-x%*%mu))
}
return(bstar)
}
data <- genData(n=n, Q=Q, sigma=sigma)
newBeta <- gibbs(data)
gibbs <- function(d, nstep=1000) {
# Gibbs sampler
Q=d$Q; x=d$x; y=d$y; n=d$n; sigma=d$sigma
# Set up to find mu
b <- matrix(0, Q, 1)
B <- diag(1000, Q) #priors are horrible, so I give it a wide variance
B.inv <- solve(B)
for (i in 1:nstep) {
# Find mu and standard errors
V.inv <- 1/sigma/sigma * crossprod(x) + B.inv
V <- solve(V.inv) #covariance matrix of beta
v <- 1/sigma/sigma * crossprod(x,y) + B.inv%*%b
sderrors <- sqrt(diag(V))
mu <- V%*%v
# And generating random values from this distn we know now
bstar <- .rMVN(1000, mu, V)
colMeans(bstar) #approaches mus
# new sigma
u1 <- u2 <- 1
# sigma <- 1/rgamma(1, u1+(n/2), u2+0.5*crossprod(y-x%*%beta))
# but we're using beta here... should I be using mu then?
sigma2 <- 1/rgamma(1, u1+(n/2), u2+0.5*crossprod(y-x%*%mu))
sigma <- sqrt(sigma2)
}
return(bstar)
}
newBeta <- gibbs(data)
newBeta
# new sigma
u1 <- u2 <- 1
# scratchData.R
# Created: 1/29/20
# Author:  Margaret Swift
# Contact: margaret.swift@duke.edu
# Simulate data and estimate betas
#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# LOADING
rm(list=ls())
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
source('../clarkFunctions2020.R')
#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# FUNCTIONS
genData <- function(n, Q, sigma) {
# Parameters
epsilon <- rnorm(n, 0, sigma)
beta <- matrix( rnorm(Q), Q, 1 )
# Simulate x and y
x <- matrix( rnorm(n*Q), n, Q )
x[,1] <- 1 #set intercept
y <- x%*%beta + epsilon
# Return data
data <- list(x=x, y=y, beta=beta, n=n, Q=Q, sigma=sigma, epsilon=epsilon)
return(data)
}
gibbs <- function(d, nstep=1000) {
# Gibbs sampler
Q=d$Q; x=d$x; y=d$y; n=d$n; sigma=d$sigma
# Set up to find mu
b <- matrix(0, Q, 1)
B <- diag(1000, Q) #priors are horrible, so I give it a wide variance
B.inv <- solve(B)
for (i in 1:nstep) {
# Find mu and standard errors
V.inv <- 1/sigma/sigma * crossprod(x) + B.inv
V <- solve(V.inv) #covariance matrix of beta
v <- 1/sigma/sigma * crossprod(x,y) + B.inv%*%b
sderrors <- sqrt(diag(V))
mu <- V%*%v
# And generating random values from this distn we know now
bstar <- .rMVN(1000, mu, V)
# new sigma
u1 <- u2 <- 1
# sigma <- 1/rgamma(1, u1+(n/2), u2+0.5*crossprod(y-x%*%beta))
# but we're using beta here... should I be using mu then?
sigma2 <- 1/rgamma(1, u1+(n/2), u2+0.5*crossprod(y-x%*%mu))
sigma <- sqrt(sigma2)
}
return(colMeans(bstar))
}
#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# MAIN
n=100; Q=5; sigma=0.1
data <- genData(n=n, Q=Q, sigma=sigma)
newBeta <- gibbs(data)
newBeta
data$beta
