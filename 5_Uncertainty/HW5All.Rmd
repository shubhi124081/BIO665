---
title: "Homework 5 Responses"
author: "Zeyi Han, Shubhi Sharma, Margaret Swift"
date: "2/24/2020"
output:
  prettydoc::html_pretty:
    theme: architect
    highlight: github
---

```{r setup, include=F}
#----------------------------------------------------------------------------
# LOADING
knitr::opts_chunk$set(echo=FALSE, eval=TRUE, cache=TRUE)
pacman::p_load(ggplot2)
source('../clarkfunctions2020.R')
# Rcpp::sourceCpp('../cppFns.cpp')
# any libraries and data here

#----------------------------------------------------------------------------
# FUNCTIONS
# put functions here

```


## Exercise 1 {#q1}
Find the MLE, the likelihood profile, and the 95% CI for waiting times that are 
exponentially distributed:

$$
L(\mathbf{y}; \lambda) = \prod_{i=1}^n \lambda e^{-y_i \lambda}
$$

```{r q1}
#----------------------------------------------------------------------------
## EXERCISE 1

```

## Exercise 2 {#q2}
Use Fisher Information to find the standard error of the mean of a normal 
sampling distribution.  Hint: you will need this:

$$
I = - \frac{d^2 \log L(\mu)}{d \mu^2}\bigg\rvert_{\hat{\mu}}
$$


```{r q2}
#----------------------------------------------------------------------------
## EXERCISE 2

```

## Exercise 3 {#q3}
Estimate the standard error for the exponential model using Fisher Information.  


```{r q3}
#----------------------------------------------------------------------------
## EXERCISE 3

```

## Exercise 4 {#q4}
For the cone example, I used the likelihood $Poi(y_i | \beta x_i)$.  Combine this 
likelihood with the prior $gamma(\beta | a, b)$ and answer the following:

a) What is the posterior density for $\beta$?

b) For simulated data sets of $n = 5$, how do the standard errors and credible 
intervals for this model compare with Fisher information?  

c) The form of the Bayesian standard error and the standard error from Fisher 
Information look different.  Can you explain why numerically they are similar? 
[Hint: think about sample size $n$].


```{r q4}
#----------------------------------------------------------------------------
## EXERCISE 4

```

## Group exercise

I want to get a feel for the uncertainty on the estimate of the variance for a 
Gaussian model for continuous observations $y$.  I would like to compare 
different methods.

1.  Find the MLE for the variance.  If you have time to kill, derive the Fisher 
information and the SE. Compare the estimates for different sample sizes.

```{r group}
#----------------------------------------------------------------------------
## GROUP EXERCISE

MLE <- function(n) {
  mu <- 0; 
  y <- rnorm(n, mu)
  return(1/n * sum((y-mu)^2))
}
```

To find the MLE, we have an approximate Gaussian density:

$$
(2\pi\sigma^2)^{-n/2}\exp\left\{ -\frac12 \frac{(\sum y_i-\mu)^2}{\sigma^2}\right\}
\propto 
(\sigma^2)^{-n/2}\exp\left\{ -\frac12 \frac{(\sum y_i-\mu)^2}{\sigma^2}\right\}
$$
took the log, found the first derivative, and set it equal to zero:

$$
\frac{d}{d\sigma^2}\left[-\frac{n}{2}\log(\sigma^2) -\frac12 (\sum y_i-\mu)^2(\sigma^2)^{-1}\right]
= -\frac{n}{2\sigma^2} + \frac{1}{2(\sigma^2)^2}\left(\sum y_i-\mu\right)^2 = 0
$$

$$
\frac{n}{2\sigma^2} = \frac{1}{2(\sigma^2)^2}\left(\sum y_i-\mu\right)^2
$$
$$
\sigma^2_{MLE} = \frac{1}{n}\left(\sum y_i-\mu\right)^2
$$

The MLEs we found for variance for $n=1, 10, 1000$ are, respectively, 
`r round(MLE(1),4)`, `r round(MLE(10),4)`, and `r round(MLE(1000),4)`. As you can
see, the variance comes closer and closer to the true variance, 1, as the sample size 
increases.

2. Generate bootstrapped estimates for the uncertainty.

3. Complete a Bayesian analysis, choose a prior. Derive the result, then use MCMC.



## Appendix {#appendix}

```{r ref.label=knitr::all_labels(), echo = T, eval = F}
```


